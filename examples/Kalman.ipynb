{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# In this example we will show the difference between fixes computed with laika\n",
    "# from raw data of the ublox receiver vs the the fixes the ublox receiver\n",
    "# computes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import numpy as np\n",
    "\n",
    "base_dir = 'example_data'\n",
    "\n",
    "\n",
    "with open(f'{base_dir}/raw_gnss_ublox/t', 'rb') as f:\n",
    "  raw_ublox_t = np.load(f)\n",
    "with open(f'{base_dir}/raw_gnss_ublox/value', 'rb') as f:\n",
    "  raw_ublox = np.load(f)\n",
    "with open(f'{base_dir}/live_gnss_ublox/t', 'rb') as f:\n",
    "  fixes_ublox_t = np.load(f)\n",
    "with open(f'{base_dir}/live_gnss_ublox/value', 'rb') as f:\n",
    "  fixes_ublox = np.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# We get the raw data into our format from the log array format\n",
    "\n",
    "from laika.raw_gnss import normal_meas_from_array\n",
    "measurements = np.array([normal_meas_from_array(arr) for arr in raw_ublox])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# initialize an astrodog with dgps corrections\n",
    "\n",
    "from laika import AstroDog\n",
    "dog = AstroDog(dgps=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Building this cache takes forever just copy it from repo\n",
    "\n",
    "from shutil import copyfile\n",
    "import os\n",
    "cache_directory = '/tmp/gnss/cors_coord/'\n",
    "try:\n",
    "  os.mkdir('/tmp/gnss/')\n",
    "except:\n",
    "  pass\n",
    "try:\n",
    "  os.mkdir(cache_directory)\n",
    "except:\n",
    "  pass\n",
    "copyfile('cors_station_positions', cache_directory + 'cors_station_positions')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/tmp/gnss/cors_coord/cors_station_positions'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from laika.raw_gnss import process_measurements, correct_measurements, calc_pos_fix\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# We want to group measurements by measurement epoch\n",
    "# this makes the kalman filter faster and is easier\n",
    "# to reason about\n",
    "grouped_t = sorted(list(set(raw_ublox_t)))                                                                                      \n",
    "grouped_meas_processed = []\n",
    "corrected_meas_arrays = []\n",
    "\n",
    "# process measurement groups\n",
    "for t in grouped_t:\n",
    "  meas = measurements[raw_ublox_t == t]\n",
    "  grouped_meas_processed.append(process_measurements(meas, dog))\n",
    "\n",
    "# correct measurement groups with an estimate position\n",
    "# that was computes with weighted-least-squares on\n",
    "# the first epoch\n",
    "# WARNING: can take up to 10min\n",
    "wls_estimate = calc_pos_fix(grouped_meas_processed[0])\n",
    "est_pos = wls_estimate[0][:3]\n",
    "for proc in tqdm(grouped_meas_processed):\n",
    "  corrected = correct_measurements(proc, est_pos, dog)\n",
    "  corrected_meas_arrays.append(np.array([c.as_array() for c in corrected]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://github.com/commaai/gnss-data-alt/raw/master/MCC/PRODUCTS/18120/final/Sta19991.sp3\n",
      "Downloading https://github.com/commaai/gnss-data-alt/raw/master/MCC/PRODUCTS/18121/final/Sta19992.sp3\n",
      "Downloading https://github.com/commaai/gnss-data-alt/raw/master/MCC/PRODUCTS/18122/final/Sta19993.sp3\n",
      "Downloading https://github.com/commaai/gnss-data/raw/master/gnss/products/1999/igs19991.sp3.Z\n",
      "Downloading https://github.com/commaai/gnss-data/raw/master/gnss/products/1999/igs19992.sp3.Z\n",
      "Downloading https://github.com/commaai/gnss-data/raw/master/gnss/products/1999/igs19993.sp3.Z\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r\n",
      "  0%| | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://geodesy.noaa.gov/corsdata/rinex/2018/121/pbl1/pbl11210.18d.gz\n",
      "HTTPS error 404\n",
      "Downloading https://alt.ngs.noaa.gov/corsdata/rinex/2018/121/pbl1/pbl11210.18d.gz\n",
      "HTTPS error 404\n",
      "File not downloaded, check availability on server.\n",
      "Downloading https://geodesy.noaa.gov/corsdata/rinex/2018/121/pbl2/pbl21210.18d.gz\n",
      "HTTPS error 404\n",
      "Downloading https://alt.ngs.noaa.gov/corsdata/rinex/2018/121/pbl2/pbl21210.18d.gz\n",
      "HTTPS error 404\n",
      "File not downloaded, check availability on server.\n",
      "Downloading https://geodesy.noaa.gov/corsdata/rinex/2018/121/hsib/hsib1210.18d.gz\n",
      "HTTPS error 404\n",
      "Downloading https://alt.ngs.noaa.gov/corsdata/rinex/2018/121/hsib/hsib1210.18d.gz\n",
      "HTTPS error 404\n",
      "File not downloaded, check availability on server.\n",
      "Downloading https://geodesy.noaa.gov/corsdata/rinex/2018/121/tibb/tibb1210.18d.gz\n",
      "Downloading https://geodesy.noaa.gov/corsdata/rinex/2018/121/capo/capo1210.18d.gz\n",
      "Downloading https://github.com/commaai/gnss-data/raw/master/gnss/products/ionex/2018/121/codg1210.18i.Z\n",
      "Downloading https://github.com/commaai/gnss-data/raw/master/gnss/products/bias/2018/CAS0MGXRAP_20181210000_01D_01D_DCB.BSX.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█| 600/600 [01:06<00:00,  8.97it/s]  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "for proc in tqdm(grouped_meas_processed):\n",
    "  corrected = correct_measurements(proc, est_pos, dog)\n",
    "  corrected_meas_arrays.append(np.array([c.as_array() for c in corrected]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█| 600/600 [00:02<00:00, 205.30it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# We run the kalman filter\n",
    "\n",
    "from kalman.models.gnss_kf import GNSSKalman\n",
    "from kalman.kalman_helpers import run_car_ekf_offline, ObservationKind\n",
    "ekf = GNSSKalman()\n",
    "init_state = ekf.x\n",
    "init_state[:3] = est_pos\n",
    "ekf.init_state(init_state)\n",
    "ekf_data = {}\n",
    "ekf_data[ObservationKind.PSEUDORANGE_GPS] = (grouped_t, corrected_meas_arrays)\n",
    "ekf_data[ObservationKind.PSEUDORANGE_RATE_GPS] = (grouped_t, corrected_meas_arrays)\n",
    "ekf_outputs = run_car_ekf_offline(ekf, ekf_data)\n",
    "\n",
    "import laika.lib.coordinates as coord\n",
    "laika_positions_t = ekf_outputs[4]\n",
    "laika_positions_ecef = ekf_outputs[0][:,:3]\n",
    "laika_positions_geodetic = coord.ecef2geodetic(laika_positions_ecef)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█| 1200/1200 [00:03<00:00, 316.10it/s]\n",
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3444: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "ublox_positions_geodetic = fixes_ublox[:,[0,1,4]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# By looking at the map, we can see that the two paths compared.\n",
    "# If you want to regenerate the gmplot you will need a google\n",
    "# maps API key\n",
    "\n",
    "import gmplot\n",
    "gmap = gmplot.GoogleMapPlotter(*laika_positions_geodetic[0])\n",
    "#gmap.apikey='...'\n",
    "gmap.plot([x[0]  for x in laika_positions_geodetic], [x[1] for x in laika_positions_geodetic], 'blue', edge_width = 5)\n",
    "gmap.plot([x[0]  for x in ublox_positions_geodetic], [x[1] for x in ublox_positions_geodetic], 'red', edge_width = 5)\n",
    "gmap.draw(\"laika_quality_check.html\")\n",
    "\n",
    "\n",
    "\n",
    "import webbrowser\n",
    "import os\n",
    "webbrowser.open('file://' + os.path.realpath(\"laika_quality_check.html\"));"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}